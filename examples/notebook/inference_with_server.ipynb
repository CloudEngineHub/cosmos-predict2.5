{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f0928c6",
   "metadata": {},
   "source": [
    "# Predict Inference (Multi-GPU)\n",
    "* to generate one single inference request use torchrun on cmd line directly\n",
    "* the input file can also specify multiple sample requests in a jsonl file (new line delimited json/json per line)\n",
    "\n",
    "    torchrun --nproc_per_node=8 examples/inference.py \\\n",
    "    -i inference_paramerters.json --checkpoint-path checkpoint.pt \\\n",
    "    --experiment predict2_lora_training_2b_cosmos_nemo_assets\n",
    "\n",
    "* to repeatedly call inference on a torchrun model the model needs to wait/block on incoming request and outputs\n",
    "* we use a helper class to  ModelServer/ModelWorker that sits on top of the model that is handling the basic synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b15a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"outputs\")\n",
    "\n",
    "if not (Path.cwd() / \"cosmos_predict2\").is_dir():\n",
    "    os.chdir(Path.cwd().parent.parent)  # Change working directory to root\n",
    "    assert (Path.cwd() / \"cosmos_predict2\").is_dir(), \"Working directory change failed.\"\n",
    "\n",
    "os.environ[\"PYTHONPATH\"] = str(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80823997",
   "metadata": {},
   "source": [
    "to use pre-trained checkpoints just specify the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f95f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmos_predict2.config import SetupArguments\n",
    "\n",
    "setup_args = SetupArguments(\n",
    "    context_parallel_size=8,\n",
    "    output_dir=output_dir,\n",
    "    model=\"2B/pre-trained\",\n",
    "    keep_going=True,\n",
    "    experiment=\"predict2_lora_training_2b_cosmos_nemo_assets\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccacb95",
   "metadata": {},
   "source": [
    "to use a local checkpoint from post-training specify the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c466bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmos_predict2.config import SetupArguments\n",
    "\n",
    "checkpoint_path = \"checkpoints/nvidia/Cosmos-Predict2.5-2B/consolidated/model.pt\"\n",
    "\n",
    "setup_args = SetupArguments(\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    context_parallel_size=8,\n",
    "    output_dir=output_dir,\n",
    "    model=\"2B/pre-trained\",\n",
    "    keep_going=True,\n",
    "    experiment=\"predict2_lora_training_2b_cosmos_nemo_assets\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c96075",
   "metadata": {},
   "source": [
    "Create simple server/worker:\n",
    "* server will create worker processes with torchrun\n",
    "* woker will wait for input request from server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c03bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmos_gradio.model_ipc.model_server import ModelServer\n",
    "\n",
    "from cosmos_predict2.gradio.video2world_worker import save_setup_args\n",
    "\n",
    "# save argumentes will be picked up by torchrun worker processes\n",
    "save_setup_args(setup_args)\n",
    "\n",
    "server = ModelServer(\n",
    "    num_gpus=setup_args.context_parallel_size,\n",
    "    factory_module=\"cosmos_predict2.gradio.video2world_worker\",\n",
    "    factory_function=\"create_worker\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e3b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmos_predict2.config import InferenceArguments\n",
    "\n",
    "asset_dir = \"datasets\"\n",
    "prompt = \"A nighttime city bus terminal gradually shifts from stillness to subtle movement. At first, multiple double-decker buses are parked under the glow of overhead lights, with a central bus labeled '87D' facing forward and stationary. As the video progresses, the bus in the middle moves ahead slowly, its headlights brightening the surrounding area and casting reflections onto adjacent vehicles. The motion creates space in the lineup, signaling activity within the otherwise quiet station. It then comes to a smooth stop, resuming its position in line. Overhead signage in Chinese characters remains illuminated, enhancing the vibrant, urban night scene.\"\n",
    "\n",
    "args = {\n",
    "    \"inference_type\": \"image2world\",\n",
    "    \"name\": \"bus_terminal\",\n",
    "    \"input_path\": os.path.join(asset_dir, \"base/bus_terminal.jpg\"),\n",
    "    \"prompt\": prompt,\n",
    "}\n",
    "\n",
    "\n",
    "validated_args = InferenceArguments(**args)\n",
    "status = server.infer(validated_args.model_dump(mode=\"json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd3fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, Video, display\n",
    "\n",
    "result = status.get(\"result\", status)\n",
    "output_videos = result.get(\"videos\", None)\n",
    "output_images = result.get(\"images\", None)\n",
    "\n",
    "if output_images:\n",
    "    for image in output_images:\n",
    "        display(Image(image))\n",
    "if output_videos:\n",
    "    for video in output_videos:\n",
    "        display(Video(video, embed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb2ac36",
   "metadata": {},
   "source": [
    "# alternatively use a json file with arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e3b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_videos = server.infer({\"args_json_file\": \"datasets/base/bus_terminal.json\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b4237b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmos-predict2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
